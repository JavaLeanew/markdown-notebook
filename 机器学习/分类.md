![image-20220725164125840](D:\home\markdown-notebook\assets\image-20220725164125840.png)

![image-20220725164156015](D:\home\markdown-notebook\assets\image-20220725164156015.png)

# 数据准备

```python
"""
MNIST数据集，这是一组由美国高中生和人口调查局员
工手写的70 000个数字的图片。
Scikit-Learn数据集结果：
Scikit-Learn加载的数据集通常具有类似的字典结构，包括：
    DESCR键，描述数据集。
    data键，包含一个数组，每个实例为一行，每个特征为一列。
    target键，包含一个带有标记的数组。
"""
from sklearn.datasets import fetch_openml
mnist=fetch_openml('mnist_784',version=1)       #通过数据集id获取开源数据集,mnist是个字典。
mnist.keys()                                    #字典结构
dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 		'DESCR', 'details', 'url'])
#获取样本和标签
X,y=mnist["data"],mnist["target"] 
X.shape 
(70000, 784)
y.shape
 (70000,)
```

因为图片是28×28像素，及每个图片含有784个特征，每个特征代表了一个像素点的强度，从0（白色）到255（黑色）。一个矩阵(28x28)可以表示这个图片，每个元素的取值为（0~255）。先来看看数据集中的一个数字，你只需要随手抓取一个实例的特征向量，将其重新形成一个28×28数组，然后使用Matplotlib的imshow（）函数将其显示出来：

```python
import numpy as np
import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt

some_digit=X.iloc[0]                                       #X中每行表示一个图片，取第一个图片 
some_digit_image=some_digit.to_numpy().reshape(28,28)      #转化为矩阵形式
#显示图片 

plt.imshow(some_digit_image,cmap='binary')
plt.axis("off")
plt.show()                    #如下图所示
#查看图片对应标签
y.iloc[0]
'5'
#注意标签是字符，大部分机器学习算法希望是数字，让我们把y转换成整数：
y=y.astype(np.uint8)
```



![](data:image/png;base64,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)

创建训练集和测试集：

```python
#MNIST数据集已经分成训练集（前6万张图片）和测试集（最后1万张图片）了
X_train,X_test,y_train,y_test=X[:60000],X[60000:],y[:60000],y[60000:]
```

# 训练二元分类器

数字5检测器：区分两个类别（5和非5）

```python
#因为是二元分类器，先处理训练集和测试集的标签
y_train_5=(y_train==5)
y_test_5=(y_test==5)
#接着挑选一个分类器并开始训练。一个好的初始选择是随机梯度下降（SGD）分类器，使用Scikit-Learn的SGDClassifier类即可。
from sklearn.linear_model import SGDClassifier

sgd_clf=SGDClassifier(random_state=42)
sgd_clf.fit(X_train,y_train_5)
#使用分类器预测
sgd_clf.predict([some_digit])
array([ True])
#预测器预测some_digit是5
```

# 性能度量



## 使用交叉验证测量准确率

使用交叉验证评估模型

```python
from sklearn.model_selection import StratifiedKFold
from sklearn.base import clone
"""
StratifiedKFold此交叉验证对象是返回分层折叠的 KFold 的变体。
通过保留每个类别的样本百分比来进行折叠。每个折叠由StratifiedKFold执行分层抽样（参见第2章）产生，其所包含的各个类的比例符合整体比例。
""" 

skfolds=StratifiedKFold(n_splits=3,random_state=42,shuffle=True)
#遍历三个折叠，train_index和test_index是每个折叠中的训练集标签和测试集标签 

for train_index,test_index in skfolds.split(X_train,y_train_5):
    clone_clf=clone(sgd_clf)                        #克隆一个sgd_clf分类器
    #获取每个折叠中的训练集示例
    X_train_folds=X_train.iloc[train_index]         
    y_train_folds=y_train_5.iloc[train_index]       
    
    #获取每个折叠中的测试集示例
    X_test_fold=X_train.iloc[test_index]
    y_test_fold=y_train_5.iloc[test_index]
     
    #为每个折叠创建分类器                                                                                                                                                                                                                                                                                                                           
    clone_clf.fit(X_train_folds,y_train_folds)
    #对每个折叠的测试集进行预测
    y_pred=clone_clf.predict(X_test_fold)
    #计算打印准确率
    n_correct=sum(y_pred==y_test_fold)
    print(n_correct/len(y_pred))
    
0.9669
0.91625
0.96785
```

用cross_val_score（）函数代替上述操作来评估SGDClassifier模型，采用K-折交叉验证法（3个折叠）。

```python
from sklearn.model_selection import cross_val_score
cross_val_score(sgd_clf,X_train,y_train_5,cv=3,scoring="accuracy")
array([0.95035, 0.96035, 0.9604 ])
```

准确率通常无法成为分类器的首要性能指标，特别是当你处理有偏数据集时（即某些类比其他类更为频繁）。因为样例中'5'的图片很少，只要多预测非5准确率就会很高；

## 混淆矩阵

评估分类器性能的更好方法是混淆矩阵，其总体思路就是统计A类别实例被分成为B类别的次数。

```python
from sklearn.model_selection import cross_val_predict
"""
与cross_val_score（）函数一样，cross_val_predict（）函数同样执行K-折交叉验证，但返回的不是评估分数，而是每个折叠的预测。y_train_pred中含有训练集中每个实例对应的预测，且是干净的。（“干净”的意思是模型预测时使用的数据在其训练期间从未见过））
""" 
y_train_pred=cross_val_predict(sgd_clf,X_train,y_train_5,cv=3)
#获取混淆矩阵
from sklearn.metrics import confusion_matrix
confusion_matrix(y_train_5,y_train_pred)
"""
混淆矩阵中的行表示实际类别，列表示预测类别。
一个完美的分类器只有真正类和真负类，所以它的混淆矩阵只会在其对角线（左上到右下）上有非零值。
"""
array([[53892,   687],
       [ 1891,  3530]], dtype=int64)
```



![](D:\home\markdown-notebook\assets\WEBRESOURCE812658edbe5f83ef8f4694eee82383b0.png)精度:
$$
精度=\frac{TP}{TP+FP}
$$
召回率：
$$
召回率=\frac{TP}{TP+FN}
$$
精度和召回率一同反应模型的性能。

## 精度和召回率

计算精度和召回率:

```python
from sklearn.metrics import precision_score,recall_score

precision_score(y_train_5,y_train_pred)#3530/(3530+687)
0.8370879772350012
recall_score(y_train_5,y_train_pred) #3530/(1891+3530)
0.6511713705958311
"""
精度为83.7%说明:当它预测一张图片为5，有83.7%的概率是正确的
召回率为65.1%说明:数字5的图片里只有65.1%被检查出来了
"""   
```

F1：
$$
F_{1} =\frac{2}{\frac{1}{精度}+\frac{1}{召回率}  }=2\times \frac{精度\times 召回率}{精度+  召回率} =\frac{TP}{TP+\frac{FN+  TP}{2} }
$$

```python
#要计算F1分数，只需要调用f1_score（）即可：
from sklearn.metrics import f1_score

f1_score(y_train_5,y_train_pred)
0.7325171197343846
```

### 精度/召回率权衡

F1分数对那些具有相近的精度和召回率的分类器更为有利。这不一定能一直符合你的期望：在某些情况下，你更关心的是精度，而另一些情况下，你可能真正关心的是召回率。

要理解这个权衡过程，我们来看看SGDClassifier如何进行分类决策。对于每个实例，它会基于决策函数计算出一个分值，如果该值大于阈值，则将该实例判为正类，否则便将其判为负类。



![](D:\home\markdown-notebook\assets\WEBRESOURCEc31294348e7bb653d3cdac0deae5b1f9.png)在这个精度/召回率权衡中，图像按其分类器评分进行排名，而高于所选决策阈值的图像被认为是正的；阈值越高，召回率越低，但是(通常)精度越高。

Scikit-Learn不允许直接设置阈值，但是可以访问它用于预测的决策分数。不是调用分类器的predict（）方法，而是调用decision_function（）方法，这种方法返回每个实例的分数，然后就可以根据这些分数，使用任意阈值进行预测了：

```python
"""
SGDClassifier分类器使用的阈值是0，所以下面代码的返回结果与predict（）方法一样（也就是True）。
"""
y_scores=sgd_clf.decision_function([some_digit])
y_scores
array([2164.22030239])

threshold=0
y_some_digit_pred=(y_scores>threshold)
array([ True])

#提升閾值
threshold=8000
y_some_digit_pred=(y_scores>threshold)
y_some_digit_pred
array([False])
"""
这证明了提高阈值确实可以降低召回率。这张图确实是5，当阈值为0时，分类器可以检测到该图，但是当阈值提高到8000时，就错过了这张图。
"""

```

**确定阈值：**

首先，使用cross_val_predict（）函数获取训练集中所有实例的分数，但是这次需要它返回的是决策分数而不是预测结果：

```python
y_scores=cross_val_predict(sgd_clf,X_train,y_train_5,cv=3,method="decision_function")
```

有了这些分数，可以使用precision_recall_curve（）函数来计算所有可能的阈值的精度和召回率：

```python
from sklearn.metrics import precision_recall_curve
#这三个数组中的数据是一一对应的，有函数关系。且阈值按从小到大排列，精度总体是上升的，召回率是下降的
precisions,recalls,thresholds=precision_recall_curve(y_train_5,y_scores)
```

最后，使用Matplotlib绘制精度和召回率相对于阈值的函数图(假设精度要求为90%，获取对应阈值)：

```python
from matplotlib.pyplot import savefig

#精度和召回率与决策阈值曲线
def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):
    plt.plot(thresholds, precisions[:-1], "b--", label="Precision", linewidth=2)
    plt.plot(thresholds, recalls[:-1], "g-", label="Recall", linewidth=2)
    plt.legend(loc="center right", fontsize=16) # Not shown in the book
    plt.xlabel("Threshold", fontsize=16)        # Not shown
    plt.grid(True)                              # Not shown
    plt.axis([-50000, 50000, 0, 1])             # Not shown


#当精度到达90%时，召回率的值
recall_90_precision = recalls[np.argmax(precisions >= 0.90)]
#当精度到达90%时，阈值的大小
threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]


plt.figure(figsize=(8, 4))                                                               
#绘制曲线
plot_precision_recall_vs_threshold(precisions, recalls, thresholds)
#在曲线中绘制出之前计算的点
plt.plot([threshold_90_precision, threshold_90_precision], [0., 0.9], "r:")                 # Not shown
plt.plot([-50000, threshold_90_precision], [0.9, 0.9], "r:")                                # Not shown
plt.plot([-50000, threshold_90_precision], [recall_90_precision, recall_90_precision], "r:")# Not shown
plt.plot([threshold_90_precision], [0.9], "ro")                                             # Not shown
plt.plot([threshold_90_precision], [recall_90_precision], "ro")                             # Not shown
savefig("precision_recall_vs_threshold_plot")                                              # Not shown
plt.show()
```

![image-20220725133127161](D:\home\markdown-notebook\assets\image-20220725133127161.png)

绘制精度与召回率的函数也可用于权衡精度与召回率:

![image-20220725133642304](D:\home\markdown-notebook\assets\image-20220725133642304.png)

使用确定的阈值进行预测：

```python
y_train_pred_90=(y_scores>=threshold_90_precision)
#检查一下预测结果的精度与召回率
precision_score(y_train_5,y_train_pred_90)
0.9000345901072293
recall_score(y_train_5,y_train_pred_90)
0.4799852425751706
```



### ROC曲线

还有一种经常与二元分类器一起使用的工具，叫作受试者工作特征曲线（简称ROC）。它与精度/召回率曲线非常相似，但绘制的不是精度和召回率，而是**真正类率（召回率的另一名称）**和**假正类率（FPR）。**FPR是被错误分为正类的负类实例比率。它等于1减去真负类率（TNR），后者是被正确分类为负类的负类实例比率，也称为特异度。因此，ROC曲线绘制的是灵敏度（召回率）和（1-特异度）的关系。

要绘制ROC曲线，首先需要使用roc_curve（）函数计算多种阈值的TPR和FPR：  

```python
from sklearn.metrics import roc_curve
fpr,tpr,thresholds=roc_curve(y_train_5,y_scores)
```

然后，使用Matplotlib绘制FPR对TPR的曲线:

```python
def plot_roc_curve(fpr, tpr, label=None):
    plt.plot(fpr, tpr, linewidth=2, label=label)
    plt.plot([0, 1], [0, 1], 'k--') # dashed diagonal
    plt.axis([0, 1, 0, 1])                                    # Not shown in the book
    plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) # Not shown
    plt.ylabel('True Positive Rate (Recall)', fontsize=16)    # Not shown
    plt.grid(True)                                            # Not shown

plt.figure(figsize=(8, 6))                                    # Not shown
plot_roc_curve(fpr, tpr)
fpr_90 = fpr[np.argmax(tpr >= recall_90_precision)]           # Not shown
plt.plot([fpr_90, fpr_90], [0., recall_90_precision], "r:")   # Not shown
plt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], "r:")  # Not shown
plt.plot([fpr_90], [recall_90_precision], "ro")               # Not shown
savefig("roc_curve_plot")                                    # Not shown
plt.show()
```

![image-20220725135547747](D:\home\markdown-notebook\assets\image-20220725135547747.png)

同样这里再次面临一个折中权衡：召回率（TPR）越高，分类器产生的假正类（FPR）就越多。粗点处突出显示了选定的比率（召回率为43.68%）  虚线表示纯随机分类器的ROC曲线、一个优秀的分类器应该离这条线越远越好（向左上角）。

有一种比较分类器的方法是**测量曲线下面积（AUC）**。完美的分类器的ROC AUC等于1，而纯随机分类器的ROC AUC等于0.5。Scikit-Learn提供计算ROC AUC的函数：

```python
from sklearn.metrics import roc_auc_score
roc_auc_score(y_train_5,y_scores)
0.9604938554008616
```

ROC曲线与PR曲线选择：当正类非常少见或者你更关注假正类而不是假负类时，应该选择PR曲线，反之则是ROC曲线。PR曲线和ROC曲线都能比较分类器的好坏。



<u>现在我们来训练一个RandomForestClassifier分类器，并比较它和SGDClassifier分类器的ROC曲线和ROC AUC分数</u>

```python
from scipy import rand
from sklearn.ensemble import RandomForestClassifier

forest_clf=RandomForestClassifier(random_state=42)
y_probas_forest=cross_val_predict(forest_clf,X_train,y_train_5,cv=3,method="predict_proba")
#y_probas_forest返回一个二维数组，其中每行代表一个实例，每列代表一个类别。每个值表示给定实例属于某个给定类别的概率。
```

```python
"""
roc_curve（）函数需要标签和分数，但是我们不提供分数，而是提供类概率。我们直接使用正类的概率作为分数值：

"""
#以正例的概率作为分数
y_scores_forest=y_probas_forest[:,1]  
fpr_forest,tpr_forest,thresholds_forest=roc_curve(y_train_5,y_scores_forest)
```

绘制ROC曲线:

```python
plt.plot(fpr,tpr,"b:",label="SGD")
plot_roc_curve(fpr_forest,tpr_forest,"Random Forest")
plt.legend(loc="lower right")
plt.show()
```

![image-20220725143241213](D:\home\markdown-notebook\assets\image-20220725143241213.png)

如图所示，RandomForestClassifier的ROC曲线看起来比SGDClassifier好很多，它离左上角更接近，因此它的ROC AUC分数也高得多。

```python
roc_auc_score(y_train_5,y_scores_forest)
0.9983436731328145
```

## 多类分类器

二元分类器在两个类中区分，而多类分类器（也称为多项分类器）可以区分两个以上的类。

![image-20220725144437240](D:\home\markdown-notebook\assets\image-20220725144437240.png)

Scikit-Learn可以检测到你尝试使用二元分类算法进行多类分类任务，它会根据情况自动运行OvR或者OvO。我们用sklearn.svm.SVC类来试试SVM分类器:

```python
from sklearn.svm import SVC
"""
这段代码使用原始目标类0到9（y_train）在训练集上对SVC进行训练，而不是以“5”和“剩余”作为目标类
（y_train_5），然后做出预测（在本例中预测正确）。而在内部，Scikit-Learn实际上训练了45个二元分类器，获得它们对图片的决策分数，然后选择了分数最高的类。
"""
svm_clf=SVC()
svm_clf.fit(X_train,y_train)
svm_clf.predict([some_digit])
"""
decision_function（）方法会返回10个分数，每个类1个，而不再是每个实例返回1个分数：
"""
some_digit_scores=svm_clf.decision_function([some_digit])
some_digit_scores
array([[ 1.72501977,  2.72809088,  7.2510018 ,  8.3076379 , -0.31087254,
         9.3132482 ,  1.70975103,  2.76765202,  6.23049537,  4.84771048]])
#最高分确实是对应数字5这个类别：
np.argmax(some_digit_scores)
5
svm_clf.classes_	#目标类的列表会存储在classes_属性中，
按值的大小排序。
array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)
svm_clf.classes_[5]
5
```

使用cross_val_score（）函数来评估SGDClassifier的准确性：

```python
cross_val_score(sgd_clf,X_train,y_train,cv=3,scoring="accuracy")
array([0.87365, 0.85835, 0.8689 ])
```

在所有的测试折叠上都超过了85%。如果是一个纯随机分类器，准确率大概是10%，所以这个结果不是太糟，但是依然有提升的空间。例如，将输入进行简单缩放。

## 误差分析

假设已经找到了一个有潜力的模型，现在你希望找到一些方法对其进一步改进。方法之一就是分析其错误类型。

<u>对于混淆矩阵：</u>

```python
#使用cross_val_predict（）函数进行预测，然后调用confusion_matrix（）函数获取混淆矩阵
y_train_pred=cross_val_predict(sgd_clf,X_train,y_train,cv=3)
conf_mx=confusion_matrix(y_train,y_train_pred)
conf_mx
array([[5635,    0,   61,   10,   16,   50,   46,    7,   66,   32],
       [   3, 6393,   95,   21,   16,   47,   15,   27,  109,   16],
       [  72,   56, 5174,   89,   69,   39,  163,   66,  212,   18],
       [  58,   32,  217, 4941,   23,  441,   32,   56,  216,  115],
       [  11,   26,   46,    6, 5298,   26,   73,   32,   87,  237],
       [  68,   23,   58,  150,   83, 4606,  174,   26,  152,   81],
       [  40,   13,   56,    6,   22,  113, 5625,    5,   36,    2],
       [  23,   24,  103,   36,  124,   40,   10, 5228,   75,  602],
       [  40,  101,  158,  122,   49,  457,   77,   35, 4666,  146],
       [  33,   18,   66,   83,  515,  127,    4,  485,  166, 4452]],
      dtype=int64)
```

```python
"""
使用matplotlib的matshow绘制矩阵，对应位置的值越大，颜色越亮
"""
plt.matshow(conf_mx,cmap=plt.cm.gray)
plt.show()
```

![image-20220725153503025](D:\home\markdown-notebook\assets\image-20220725153503025.png)

混淆矩阵看起来很不错，因为大多数图片都在主对角线上，这说明它们被正确分类。数字5看起来比其他数字稍稍暗一些，这可能意味着数据集中数字5的图片较少，也可能是分类器在数字5上的执行效果不如在其他数字上好。实际上，你可能会验证这两者都属实。

首先，你需要将混淆矩阵中的每个值除以相应类中的图片数量，这样你比较的就是错误率而不是错误的绝
对值（后者对图片数量较多的类不公平）：

```python
row_sums=conf_mx.sum(axis=1,keepdims=True)
norm_conf_mx=conf_mx/row_sums
#用0填充对角线，只保留错误
np.fill_diagonal(norm_conf_mx,0)
plt.matshow(norm_conf_mx,cmap=plt.cm.gray)
plt.show()
```

![image-20220725154222399](D:\home\markdown-notebook\assets\image-20220725154222399.png)

现在可以清晰地看到分类器产生的错误种类了。记住，每行代表实际类，而每列表示预测类。第8列看起来非常亮，说明有许多图片被错误地分类为数字8了。通过上图来看，你的精力可以花在改进数字8的分类错误上。例如，可以试着收集更多看起来像数字8的训练数据，以便分类器能够学会将它们与真实的数字区分开来。或者，也可以开发一些新特征来改进分类器——例如，写一个算法来计算闭环的数量（例如，数字8有两个，数字6有一个，数字5没有）。

## 多标签分类

到目前为止，每个实例都只会被分在一个类里。而在某些情况下，你希望分类器为每个实例输出多个类。

例如，人脸识别的分类器：如果在一张照片里识别出多个人怎么办？当然，应该为识别出来的每个人都附上一个标签。假设分类器经过训练，已经可以识别出三张脸——爱丽丝、鲍勃和查理，那么当看到一张爱丽丝和查理的照片时，它应该输出[1，0，1]（意思是“是爱丽丝，不是鲍勃，是查理”）这种输出多个二元标签的分类系统称为多标签分类系统。

## 多输出分类

简单来说，它是多标签分类的泛化，其标签也可以是多类的（比如它可以有两个以上可能的值）。

为了说明这一点，构建一个系统去除图片中的噪声。给它输入一张有噪声的图片，它将（希望）输出一张干净的数字图片，与其他MNIST图片一样，以像素强度的一个数组作为呈现方式。请注意，这个分类器的输出是多个标签（一个像素点一个标签），每个标签可以有多个值（像素强度范围为0到225）。
