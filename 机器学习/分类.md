# 数据准备

```python
"""
MNIST数据集，这是一组由美国高中生和人口调查局员
工手写的70 000个数字的图片。
Scikit-Learn数据集结果：
Scikit-Learn加载的数据集通常具有类似的字典结构，包括：
    DESCR键，描述数据集。
    data键，包含一个数组，每个实例为一行，每个特征为一列。
    target键，包含一个带有标记的数组。
"""
from sklearn.datasets import fetch_openml
mnist=fetch_openml('mnist_784',version=1)            #通过数据集id获取开源数据集,mnist是个字典。
mnist.keys()                                         #字典结构
dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])
#获取样本和标签
X,y=mnist["data"],mnist["target"] 
X,y=mnist["data"],mnist["target"]
X.shape 
(70000, 784)
y.shape
 (70000,)


```

因为图片是28×28像素，及每个图片含有784个特征，
每个特征代表了一个像素点的强度，从0（白色）到255（黑色）。一个矩阵(28x28)可以表示这个图片，每个元素的取值为（0~255）。先来
看看数据集中的一个数字，你只需要随手抓取一个实例的特征向量，将
其重新形成一个28×28数组，然后使用Matplotlib的imshow（）函数将
其显示出来：

```python
import numpy as np
import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt

some_digit=X.iloc[0]                                       #X中每行表示一个图片，取第一个图片 
some_digit_image=some_digit.to_numpy().reshape(28,28)      #转化为矩阵形式
#显示图片 

plt.imshow(some_digit_image,cmap='binary')
plt.axis("off")
plt.show()                    #如下图所示
#查看图片对应标签
y.iloc[0]
'5'
#注意标签是字符，大部分机器学习算法希望是数字，让我们把y转
换成整数：
y=y.astype(np.uint8)
```



![](data:image/png;base64,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)

创建训练集和测试集：

```python
#MNIST数据集已经分成训练集（前6
万张图片）和测试集（最后1万张图片）了
X_train,X_test,y_train,y_test=X[:60000],X[60000:],y[:60000],y[60000:]
```

# 训练二元分类器

数字5检测器：区分两个类别（5和非5）

```python
#因为是二元分类器，先处理训练集和测试集的标签
y_train_5=(y_train==5)
y_test_5=(y_test==5)
#接着挑选一个分类器并开始训练。一个好的初始选择是随机梯度
下降（SGD）分类器，使用Scikit-Learn的SGDClassifier类即可。
from sklearn.linear_model import SGDClassifier

sgd_clf=SGDClassifier(random_state=42)
sgd_clf.fit(X_train,y_train_5)
#使用分类器预测
sgd_clf.predict([some_digit])
array([ True])
                        #预测器预测some_digit是5
```

# 性能度量



## 使用交叉验证测量准确率

使用交叉验证评估模型

```python
from sklearn.model_selection import StratifiedKFold
from sklearn.base import clone
"""
StratifiedKFold此交叉验证对象是返回分层折叠的 KFold 的变体。
通过保留每个类别的样本百分比来进行折叠。
每个折叠由StratifiedKFold执行分层抽样（参见第2章）产生，其
所包含的各个类的比例符合整体比例。
""" 

skfolds=StratifiedKFold(n_splits=3,random_state=42,shuffle=True)
#遍历三个折叠，train_index和test_index是每个折叠中的训练集标签和测试集标签 

for train_index,test_index in skfolds.split(X_train,y_train_5):
    clone_clf=clone(sgd_clf)                        #克隆一个sgd_clf分类器
    #获取每个折叠中的训练集示例
    X_train_folds=X_train.iloc[train_index]         
    y_train_folds=y_train_5.iloc[train_index]       
    
    #获取每个折叠中的测试集示例
    X_test_fold=X_train.iloc[test_index]
    y_test_fold=y_train_5.iloc[test_index]
     
    #为每个折叠创建分类器                                                                                                                                                                                                                                                                                                                           
    clone_clf.fit(X_train_folds,y_train_folds)
    #对每个折叠的测试集进行预测
    y_pred=clone_clf.predict(X_test_fold)
    #计算打印准确率
    n_correct=sum(y_pred==y_test_fold)
    print(n_correct/len(y_pred))
    
0.9669
0.91625
0.96785
```

用cross_val_score（）函数代替上述操作来评估SGDClassifier模型，采
用K-折交叉验证法（3个折叠）。

```python
from sklearn.model_selection import cross_val_score
cross_val_score(sgd_clf,X_train,y_train_5,cv=3,scoring="accuracy")
array([0.95035, 0.96035, 0.9604 ])
```

准确率通常无法成为分类器的首要性能指标，特别是当你处
理有偏数据集时（即某些类比其他类更为频繁）。因为样例中'5'的图片很少，只要多预测非5准确率就会很高；

## 混淆矩阵

评估分类器性能的更好方法是混淆矩阵，其总体思路就是统计A类
别实例被分成为B类别的次数。

```python
from sklearn.model_selection import cross_val_predict
"""
与cross_val_score（）函数一样，cross_val_predict（）函数同
样执行K-折交叉验证，但返回的不是评估分数，而是每个折叠的预测。
y_train_pred中含有训练集中每个实例对应的预测，且是干净的。（“干净”的意思是
模型预测时使用的数据在其训练期间从未见过））
""" 
y_train_pred=cross_val_predict(sgd_clf,X_train,y_train_5,cv=3)
#获取混淆矩阵
from sklearn.metrics import confusion_matrix
confusion_matrix(y_train_5,y_train_pred)
"""
混淆矩阵中的行表示实际类别，列表示预测类别。
一个完美的
分类器只有真正类和真负类，所以它的混淆矩阵只会在其对角线（左上
到右下）上有非零值。
"""
array([[53892,   687],
       [ 1891,  3530]], dtype=int64)
```



![](D:\home\markdown-notebook\assets\WEBRESOURCE812658edbe5f83ef8f4694eee82383b0.png)精度:

![](D:\home\markdown-notebook\assets\WEBRESOURCE25dccadecada60f9e73a40f7914cc39f.png)召回率：

![](D:\home\markdown-notebook\assets\WEBRESOURCEe64ef84f8e7b228429b40879094c2a61.png)精度和召回率一同反应模型的性能。

## 精度和召回率

计算精度和召回率:

```python
from sklearn.metrics import precision_score,recall_score
precision_score(y_train_5,y_train_pred)#3530/(3530+687)
0.8370879772350012
recall_score(y_train_5,y_train_pred) #3530/(1891+3530)
0.6511713705958311
"""
精度为83.7%说明:当它预测一张图片为5，有83.7%的概率是正确的
召回率为65.1%说明:数字5的图片里只有65.1%被检查出来了
"""   
```

F1：

![](D:\home\markdown-notebook\assets\WEBRESOURCE123eaa2ed7dadb5b38e648a240066433.png)F1分数将精度和召回率结合起来，对那些具有相近的精度和召回率的分类器更为有利。

```python
#要计算F1分数，只需要调用f1_score（）即可：
from sklearn.metrics import f1_score
f1_score(y_train_5,y_train_pred)
0.7325171197343846
```

### 精度/召回率权衡

F1分数对那些具有相近的精度和召回率的分类器更为有利。这不一
定能一直符合你的期望：在某些情况下，你更关心的是精度，而另一些
情况下，你可能真正关心的是召回率。

要理解这个权衡过程，我们来看看SGDClassifier如何进行分类决
策。对于每个实例，它会基于决策函数计算出一个分值，如果该值大于
阈值，则将该实例判为正类，否则便将其判为负类。



![](D:\home\markdown-notebook\assets\WEBRESOURCEc31294348e7bb653d3cdac0deae5b1f9.png)在这个精度/召回率权衡中，图像按其分类器评分进行排名，而
高于所选决策阈值的图像被认为是正的；阈值越高，召回率越低，但是
（通常）精度越高。

Scikit-Learn不允许直接设置阈值，但是可以访问它用于预测的决
策分数。不是调用分类器的predict（）方法，而是调用
decision_function（）方法，这种方法返回每个实例的分数，然后就
可以根据这些分数，使用任意阈值进行预测了：

```python
"""
SGDClassifier分类器使用的阈值是0，所以下面代码的返回结果与
predict（）方法一样（也就是True）。
"""
y_scores=sgd_clf.decision_function([some_digit])
y_scores
array([2164.22030239])
threshold=0
y_some_digit_pred=(y_scores>threshold)
array([ True])
#提升閾值
threshold=8000
y_some_digit_pred=(y_scores>threshold)
y_some_digit_pred
array([False])
"""
这证明了提高阈值确实可以降低召回率。这张图确实是5，当阈值
为0时，分类器可以检测到该图，但是当阈值提高到8000时，就错过了
这张图。
"""

```

确定阈值：

首先，使用
cross_val_predict（）函数获取训练集中所有实例的分数，但是这次


需要它返回的是决策分数而不是预测结果：

```python
y_scores=cross_val_predict(sgd_clf,X_train,y_train_5,cv=3,method="decision_function")
```

有了这些分数，可以使用precision_recall_curve（）函数来计算
所有可能的阈值的精度和召回率：

```python
from sklearn.metrics import precision_recall_curve
precisions,recalls,thresholds=precision_recall_curve(y_train_5,y_scores)
```

最后，使用Matplotlib绘制精度和召回率相对于阈值的函数图：

```python

```

